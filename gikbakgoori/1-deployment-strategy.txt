# Exchange Service 배포 전략

## 1. 로컬 개발 환경 [구현 완료]

### 기본 구성
- 백엔드 서버 (단일 인스턴스)
- Kafka + Zookeeper (docker-compose-local.yml)
- Kafka UI

### 설정
```yaml
spring:
  profiles:
    active: local
  kafka:
    enabled: true
    bootstrap-servers: localhost:9092

zookeeper:
  connect-string: localhost:2181

app:
  websocket:
    endpoint: ws://localhost:8080/ws/exchange
```

### 특징
- 단순한 구성으로 빠른 개발/테스트
- 로컬 환경에서 Kafka/Zookeeper 테스트 가능
- 모든 기능이 단일 인스턴스에서 동작

## 2. Docker 개발 환경 [구현 완료]

### 기본 구성
- 백엔드 서버 (2개 인스턴스: backend1, backend2)
- Kafka + Zookeeper
- Kafka UI

### Docker Compose 설정
```yaml
version: '3'
services:
  backend1:
    build: .
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - LOG_LEVEL=DEBUG
    ports:
      - "8080:8080"

  backend2:
    build: .
    environment:
      - SPRING_PROFILES_ACTIVE=docker
      - LOG_LEVEL=DEBUG
    ports:
      - "8081:8080"

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    
  kafka:
    image: confluentinc/cp-kafka:latest
    
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
```

### 특징
- 실제 운영 환경과 유사한 구성
- Leader Election 테스트 가능
- 리더/팔로워 동작 검증
- 장애 복구 테스트 가능

## 3. 운영 환경 (Kubernetes) [구현 예정]

### 기본 구성
- Ingress Controller (Nginx)
- Exchange Service Deployment
- MSK (Amazon Managed Streaming for Kafka)

### Kubernetes 리소스
1. Deployment
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: exchange-service
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: exchange-service
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "prod"
        - name: LOG_LEVEL
          value: "INFO"
```

2. Service
```yaml
apiVersion: v1
kind: Service
metadata:
  name: exchange-service
spec:
  selector:
    app: exchange-service
  ports:
  - port: 80
    targetPort: 8080
```

3. Ingress
```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: exchange-service
  annotations:
    kubernetes.io/ingress.class: "nginx"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "3600"
```

### 배포 구성
1. 현재 구현된 구성
   ```
   [리더 Pod]
   거래소 -> Pod -> WebSocket -> Clients

   [팔로워 Pod]
   리더십 모니터링 -> 장애 시 리더로 전환
   ```

2. 다음 구현 예정 (Kafka 통합)
   ```
   [리더 Pod]
   거래소 -> Pod -> Kafka

   [팔로워 Pod]
   Kafka -> Pod -> Clients
   ```

### 특징
- Rolling Update 지원
- Pod Auto Scaling
- Leader Election을 통한 고가용성
- 리더 장애 시 자동 복구

## 주요 고려사항

1. 무중단 배포 [구현 예정]
   - Rolling Update 전략
   - Readiness Probe로 정상 여부 확인
   - 세션 드레이닝 적용

2. 장애 대응 [일부 구현]
   - [✓] Pod 장애: 리더/팔로워 자동 전환
   - [ ] Kafka 장애: WebSocket 모드로 자동 전환 (구현 예정)
   - [✓] 리더 장애: 팔로워가 자동으로 리더로 전환

3. 모니터링 [일부 구현]
   - [✓] 로깅 시스템 구현 (LOG_LEVEL 환경변수)
   - [✓] 리더십 상태 모니터링
   - [ ] Prometheus + Grafana (구현 예정)
   - [ ] 거래소 연결 상태 대시보드 (구현 예정)

4. 보안 [구현 예정]
   - HTTPS/WSS (Cert-Manager)
   - Network Policy
   - RBAC 